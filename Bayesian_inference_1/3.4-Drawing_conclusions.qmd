---
title: "Drawing conclusions"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    embed-resources: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
    link-external-newwindow: true
bibliography: Bayes.bib
csl: evolution.csl
---

## Next steps

```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(readxl)
library(cowplot)
ggplot2::theme_set(theme_cowplot(font_size = 18))

library(cmdstanr)
library(brms)
library(bayesplot)

library(bayestestR)
```

- Are these models "good"?
  - Posterior predictive checks and highest density intervals
- Are parameter estimates credibly different from zero?
  - Regions of practical equivalence
- Which model is "better"?
  - Model comparison


## Making decisions with data

- Bayesian inference doesn't solve the "P-value" problem
- Null hypothesis significance testing (NHST) can still be done
  - Whether it should or not


## Convenience tools

- `rethinking` and `ulam()` are great for learning
  - Explicitly ask for everything
  - Must set priors
- We'll start using the [`brms` package](https://paul-buerkner.github.io/brms/)
  - Automates some aspects of model fitting
  - Uses R model syntax
  - Converts factors
  - Sets default flat priors (so you should set your own)
  - Easier to work with posteriors (`tidybayes`, `bayestestR`)
  


## Load the `Snakes` data

```{r}
#| echo: false
Snakes <- read_excel("Data/Snakes.xlsx") |> 
  rename(Species = SPECIES,
         Family = FAMILY,
         ForagingMode = `FORAGING MODE (AMBUSH/ACTIVE)`,
         SVL = `SNOUT-VENT LENGTH (CM)`,
         RPM = `AVERAGE RPM (PROP)`) |> 
  filter(!(Family %in% c("Aniliidae", "Grayiinae", "Homalopsidae"))) |> 
  dplyr::select(ForagingMode, SVL, RPM) |> 
  mutate(ForagingMode = factor(ForagingMode),
         log10SVL = log10(SVL))

str(Snakes)
```


## Fit two models with `brm()`

- Use `lm()` model syntax
- Set prior for all `b` parameters: intercepts and slopes
  - Customize later

```{r}
#| echo: true
#| output: false

library(brms)
options(brms.backend = "cmdstanr")

fm_add <- brm(RPM ~ ForagingMode + log10SVL - 1, data = Snakes,
              prior = set_prior("normal(0, 0.5)", class = "b"), iter = 5e3)

fm_inter <- brm(RPM ~ ForagingMode * log10SVL, data = Snakes,
              prior = set_prior("normal(0, 0.5)", class = "b"), iter = 5e3)
```


## Prior summary

```{r}
#| echo: true

prior_summary(fm_add)
```


## Model Summaries: Additive model

```{r}
#| echo: true

summary(fm_add)
```


## Model Summaries: Interaction model

```{r}
#| echo: true

summary(fm_inter)
```


## Plot posteriors

[`bayesplot`](http://mc-stan.org/bayesplot/) has many functions for working with models.

```{r}
#| echo: true
#| output-location: slide

library(bayesplot)
color_scheme_set(scheme = "red")

post <- as_draws_array(fm_add)

mcmc_combo(fm_add, regex_pars = "b",
           combo = c("dens_overlay", "rank_overlay"))
```


## Posterior predictive checks

Plot the distribution of `RPM` and a sample of 100 draws from the posterior ($y_{rep}$})

```{r}
#| echo: true
#| output-location: slide

pp_check(fm_add, ndraws = 100)
```


## Posterior predictive checks

Plot histograms of samples from the posteriors separately for `ForagingMode` with the mean of `RPM` for each.

```{r}
#| echo: true
#| output-location: slide
#| warning: false
#| message: false

pp_check(fm_add, type = "stat_grouped", group = "ForagingMode",
         stat = "mean",
         ndraws = 500)
```


## Do foraging modes differ in mean RPM?

Three approaches

1. Compare credible intervals of posteriors for Active and Ambush
2. Compare the *difference* in the posteriors to 0
3. Compare the *difference* in the posteriors to 0 $\pm$ some small value

. . .

More context and practice in Unit 5


## HPDI bands

Predict across a range of `log10SVL` for each level of `ForagingMode`.

```{r}
#| echo: true

pred_values <- crossing(
  log10SVL = seq(1.3, 2.5, length.out = 100),
  ForagingMode = levels(Snakes$ForagingMode)
)
pred_values
```


## Two kinds of posterior intervals

1. HDIs for the parameter estimates
    - Credible ranges for expected values
    - `posterior_epred()`
2. HDIs for new or observed values ("posterior predictive distribution")
    - Include the uncertainty ($\sigma$)
    - Wider than expected values intervals
    - `posterior_predict()`


## Predicting with brms

```{r}
#| echo: true
p_pred <- posterior_epred(fm_add, newdata = pred_values)
str(p_pred)
```

- 10,000 draws for each of 200 combinations of `log10SVL` and `ForagingMode`.
- Each column is 1 *row* of `pred_values`.


## Computing credible intervals

- Calculate median and 89% quantile interval ($\sim$ HDI)
- `apply()` `quantile()` across the columns (`MARGIN = 2`) of `p_pred`

```{r}
#| echo: true
#| output-location: slide

pred_values <- pred_values |> 
  mutate(Q50 = apply(p_pred, MARGIN = 2, FUN = quantile, prob = 0.5),
         Q5.5 = apply(p_pred, MARGIN = 2, FUN = quantile, prob = 0.055),
         Q94.5 = apply(p_pred, MARGIN = 2, FUN = quantile, prob = 0.945))
pred_values
```


## Plotting credible intervals

```{r}
#| echo: true
#| output-location: slide

ggplot() +
  geom_point(data = Snakes, aes(log10SVL, RPM, color = ForagingMode),
             size = 3) +
  geom_ribbon(data = pred_values,
              aes(x = log10SVL, ymin = Q5.5, ymax = Q94.5,
                  fill = ForagingMode), alpha = 0.25) +
  geom_line(data = pred_values,
            aes(x = log10SVL, y = Q50, color = ForagingMode)) +
  scale_color_manual(values = c("red", "blue")) +
  scale_fill_manual(values = c("red", "blue"))
```


## Compare HDIs

```{r}
#| echo: true
post <- as_draws_df(post) |> as_tibble()

library(bayestestR)

hdi(post$b_ForagingModeActive, ci = 0.89)
hdi(post$b_ForagingModeAmbush, ci = 0.89)
```


## Compare credible intervals

- Highest density vs. equal tails

```{r}
#| echo: true

ci(post[, 1:4], method = "HDI", ci = 0.89)
ci(post[, 1:4], method = "ETI", ci = 0.89)
```


## HDI of the *difference* between Ambush and Active

Use `mutate()` to calculate the difference for each sample

```{r}
#| echo: true

post <- post |> 
  mutate(d = b_ForagingModeAmbush - b_ForagingModeActive)
post |> select(1:3, 10)
```


## HDI of Ambush - Active

```{r}
#| echo: true

ggplot(post, aes(d)) +
  geom_density(linewidth = 2) +
  labs(x = "Ambush - Active", y = "Density")
```


## HDI of Ambush - Active

```{r}
#| echo: true

hdi(post$d, method = "HDI", ci = 0.89)
hdi(post$d, method = "ETI", ci = 0.89)
```


## Region of practical equivalence

> "A difference of zero plus or minus some small amount is for practical purposes 'not different' from zero."

[Easystats](https://easystats.github.io/bayestestR/articles/region_of_practical_equivalence.html) has a good introduction. Additional reading:

- Kruschke [-@Kruschke2010-wi; @Kruschke2015-rp; @Kruschke2018-mg]
- Kruschke et al. [-@Kruschke2012-sb]


## ROPE

- Uses `rope_range()` to automatically find the most suitable range for comparison.
    - Think about what interval you consider practically equivalent
    - Kruschke also recommends $\pm 0.1 \cdot sd_y$ 
- Recommended to use the entire posterior to determine the percentage in the ROPE


## ROPE

```{r}
#| echo: true

rr <- c(-0.1 * sd(Snakes$RPM), 0.1 * sd(Snakes$RPM))
rr
rope(post$d, ci = 1, range = rr)
```


## ROPE vs. HDI

```{r}
#| echo: true

ggplot(post, aes(d)) +
  geom_density(linewidth = 1.5) +
  geom_vline(xintercept = rr,
             color = "red", linewidth = 1.5) +
  geom_vline(xintercept = as.numeric(hdi(post$d))[2:3],
             color = "blue", linewidth = 1.5) +
  labs(x = "Ambush - Active", y = "Density")
```


## Leave-one-out Cross Validation (LOO-CV)

Stan uses an approximation of the LOO-CV [@Vehtari2017-we; @Gelman2014-jh; @Burkner2021-mp]

```{r}
#| echo: true

fm_add <- add_criterion(fm_add, "loo")
fm_inter <- add_criterion(fm_inter, "loo")

loo_compare(fm_add, fm_inter)
```


## Model weights

Distribute the expected predictive ability across 100%.

```{r}
#| echo: true

model_weights(fm_add, fm_inter, weights = "loo")
```

- Interaction model has most of the model weight.
- Not 100% though (model averaging in Unit 5)


## No decision is completely objective

- P-values, confidence intervals
- AIC, AICc
- Credible intervals, HDIs
- ROPEs
- LOO-CV values

More discussion, detail, examples in Unit 5.


## References

::: {#refs}
:::

