---
title: "Likelihood"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
    link-external-newwindow: true
bibliography: Bayes.bib
---

## Probability

```{r}
#| label: setup
#| echo: false
#| warning: false
#| message: false

library(tidyverse)
library(cowplot)
ggplot2::theme_set(theme_cowplot())
library(lubridate)

library(Data4Ecologists)
library(rethinking)
```

The probability of an event is the proportion of times the event would occur if a random trial is repeated infinitely under constant conditions.


## Probability

The probability of an event is the **proportion** of times the event **would** occur **if** a **random** trial is repeated **infinitely** under **constant conditions**.

- proportion
- would occur
- if
- random trial
- infinitely
- constant conditions


## Basics of probability

Probabilities are proportions.

Pr[event] is the abbreviation for “the probability of event A occurring.”

- $Pr[Rain] = 0.50$: Rain
- $Pr[Rain'] = 0.50$: *Not* Rain

The range of probabilities for an event is 0 $\rightarrow$ 1 (including 0 and 1).


## Probability to Likelihood

- For data and a set of parameter values, the (model) likelihood is the product of all the individual probabilities
- Proportions are an easy place to start
  - Only 1 data point: # of successes for a # of trials
  - Only 1 parameter: Probability of success


## Common carp (*Cyprinus carpio*)

![](https://upload.wikimedia.org/wikipedia/commons/d/dc/%D0%9A%D0%B0%D1%80%D0%BF.jpg)


### Carp movement data

- 71 carp that approached a dam or lock on the Mississippi River^[Riesgraf AT, Finger JS, Zielinski DP, Dennis III CE, Whitty JM, Sorensen PW. 2022. Evaluation of a broadband sound projected from the gates of a navigation lock in the Mississippi River shows it to be a weak deterrent for common carp and unable to block passage. *Management of Biological Invasions* 13]
- `Pass` is `0` if the fish did not enter, `1` if it did
- Binomial distribution / Bernoulli trials
  - `Pass == 1` is "Success"

What is the probability of a carp entering the dam or lock?


# Carp movement data

```{r}
#| echo: true
Carp <- carppassage |> 
  filter(Sound == 0) |> 
  mutate(Date = mdy(Date)) |> 
  arrange(Date) |> 
  select(Pass, FishID, Date)

Carp
```


## Carp movement data

```{r}
#| echo: true

Carp |> 
  group_by(Pass) |> 
  count()
```

- 9 of 71 carp passed
- Pr[Pass] = 9/71 = `r 9/71`


## Likelihood for binomial data

- 9 successes in 72 trials
- Probability is 0.5, 0.25, or 0.1
- The binomial probability is the model likelihood
  - Not true for anything more complex

```{r}
#| echo: true

dbinom(9, 72, prob = 0.5)
dbinom(9, 72, prob = 0.25)
dbinom(9, 72, prob = 0.1)
```


## Visualizing binomial probabilities

- Probability of exactly `x` successes in 71 trials
- Underlying probability is 9/71

```{r}
#| echo: true
#| output-location: slide

ggplot() +
  geom_bar(data = tibble(Pass = 0:25,
                         Density = dbinom(Pass, 71, prob = 9/71)),
           aes(x = Pass, y = Density),
           stat = "identity") +
  geom_bar(data = tibble(Pass = 9,
                         Density = dbinom(Pass, 71, prob = 9/71)),
           aes(x = Pass, y = Density),
           stat = "identity",
           fill = "red") +
  labs(title = "0 to 25 successes in 71 trials for P = 9/71")
```


## Logistic regression via maximum likelihood

- `~ 1` tells `glm()` to fit only an intercept
- Specify `"binomial"` response

```{r}
#| echo: true
#| output-location: slide

fm <- glm(Pass ~ 1, data = Carp,
          family = "binomial")
summary(fm)
```


## Compare to raw proportion

- Convert logit `(Intercept)` to probability 
- Also using `rethinking::logistic()`

```{r}
#| echo: true
1/(1 + exp(-coef(fm)))
logistic(coef(fm))
9/71
```


## What does this likelihood represent?

Frequentist interpretation


## What have we learned so far?

- Maximum likelihood estimate of the mean of Bernoulli trials is the proportion of successes.
  - Note: no additional predictors; "mean" only
- Can approximate a confidence interval by one of ~5 methods
- We can do all this without Bayes or sampling

<br />

<center>
*So why Bayesian inference?*
</center>

