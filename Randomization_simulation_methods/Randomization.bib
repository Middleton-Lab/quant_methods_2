% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

@ARTICLE{Storey2003-mz,
  title       = "Statistical significance for genomewide studies",
  author      = "Storey, John D and Tibshirani, Robert",
  abstract    = "With the increase in genomewide experiments and the sequencing
                 of multiple genomes, the analysis of large data sets has
                 become commonplace in biology. It is often the case that
                 thousands of features in a genomewide data set are tested
                 against some null hypothesis, where a number of features are
                 expected to be significant. Here we propose an approach to
                 measuring statistical significance in these genomewide studies
                 based on the concept of the false discovery rate. This
                 approach offers a sensible balance between the number of true
                 and false positives that is automatically calibrated and
                 easily interpreted. In doing so, a measure of statistical
                 significance called the q value is associated with each tested
                 feature. The q value is similar to the well known p value,
                 except it is a measure of significance in terms of the false
                 discovery rate rather than the false positive rate. Our
                 approach avoids a flood of false positive results, while
                 offering a more liberal criterion than what has been used in
                 genome scans for linkage.",
  journal     = "Proc. Natl. Acad. Sci. U. S. A.",
  volume      =  100,
  number      =  16,
  pages       = "9440--9445",
  month       =  aug,
  year        =  2003,
  url         = "http://dx.doi.org/10.1073/pnas.1530509100",
  keywords    = "xx Archived/FDR;Module - Randomization;Quantitative Methods",
  language    = "en",
  issn        = "0027-8424",
  pmid        = "12883005",
  doi         = "10.1073/pnas.1530509100",
  pmc         = "PMC170937",
  original_id = "cb386ad5-cd57-0385-8c7c-4dbdf850cef6"
}

@ARTICLE{Benjamini1995-cw,
  title       = "Controlling the False Discovery Rate: A Practical and Powerful
                 Approach to Multiple Testing",
  author      = "Benjamini, Yoav and Hochberg, Yosef",
  abstract    = "The common approach to the multiplicity problem calls for
                 controlling the familywise error rate (FWER). This approach,
                 though, has faults, and we point out a few. A different
                 approach to problems of multiple significance testing is
                 presented. It calls for controlling the expected proportion of
                 falsely rejected hypotheses-the false discovery rate. This
                 error rate is equivalent to the FWER when all hypotheses are
                 true but is smaller otherwise. Therefore, in problems where
                 the control of the false discovery rate rather than that of
                 the FWER is desired, there is potential for a gain in power. A
                 simple sequential Bonferroni-type procedure is proved to
                 control the false discovery rate for independent test
                 statistics, and a simulation study shows that the gain in
                 power is substantial. The use of the new procedure and the
                 appropriateness of the criterion are illustrated with
                 examples.",
  journal     = "J. R. Stat. Soc. Series B Stat. Methodol.",
  volume      =  57,
  number      =  1,
  pages       = "289--300",
  year        =  1995,
  url         = "http://www.jstor.org/stable/2346101",
  keywords    = "xx Archived/FDR;Module - Randomization;Quantitative Methods",
  issn        = "1369-7412, 0035-9246",
  original_id = "f82b0881-aae3-0dd0-9d8d-150bd55279dc"
}

@ARTICLE{Curran-Everett2000-qv,
  title       = "Multiple comparisons: philosophies and illustrations",
  author      = "Curran-Everett, Douglas",
  abstract    = "Statistical procedures underpin the process of scientific
                 discovery. As researchers, one way we use these procedures is
                 to test the validity of a null hypothesis. Often, we test the
                 validity of more than one null hypothesis. If we fail to use
                 an appropriate procedure to account for this multiplicity,
                 then we are more likely to reach a wrong scientific
                 conclusion[---]we are more likely to make a mistake. In
                 physiology, experiments that involve multiple comparisons are
                 common: of the original articles published in 1997 by the
                 American Physiological Society, ~40\% cite a multiple
                 comparison procedure. In this review, I demonstrate the
                 statistical issue embedded in multiple comparisons, and I
                 summarize the philosophies of handling this issue. I also
                 illustrate the three procedures[---]Newman-Keuls, Bonferroni,
                 least significant difference[---]cited most often in my
                 literature review; each of these procedures is of limited
                 practical value. Last, I demonstrate the false discovery rate
                 procedure, a promising development in multiple comparisons.
                 The false discovery rate procedure may be the best practical
                 solution to the problems of multiple comparisons that exist
                 within physiology and other scientific disciplines.",
  journal     = "Am. J. Physiol. Regul. Integr. Comp. Physiol.",
  volume      =  279,
  number      =  1,
  pages       = "R1--8",
  month       =  jul,
  year        =  2000,
  url         = "http://ajpregu.physiology.org/content/279/1/R1",
  keywords    = "xx Archived/FDR;Module - Randomization;Quantitative Methods",
  issn        = "0363-6119",
  original_id = "42551e24-cdd3-0e20-8f12-bfcc634958d6"
}
